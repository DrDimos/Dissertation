{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "lmswR-NG-Esl",
        "_qnSSZ3wkbw7",
        "OnQaOZ8KkmS6"
      ],
      "mount_file_id": "1E3WkLTWtwdhOjYYC7ixyM4C7qaDAzzVi",
      "authorship_tag": "ABX9TyO9qhRSyYXd3OvZ9dL2FKLC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrDimos/Dissertation/blob/main/Selected_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Library Imports\n",
        "\n",
        "1.   NumPy\n",
        "2.   Tensorflow\n",
        "1.   Matplotlib\n",
        "2.   Time"
      ],
      "metadata": {
        "id": "lmswR-NG-Esl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *NumPy Library Imports*"
      ],
      "metadata": {
        "id": "xf7ygBEkSEv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from numpy import genfromtxt\n",
        "from numpy import argmin, argmax"
      ],
      "metadata": {
        "id": "-ygBkzoE9g7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *TensorFlow Library Imports*"
      ],
      "metadata": {
        "id": "g7sH0pV-SM_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras,metrics, math\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Input, LSTM, ConvLSTM1D, Conv1D, MaxPooling1D\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.metrics import Accuracy, CategoricalAccuracy, Precision, PrecisionAtRecall, Recall, RecallAtPrecision, AUC, SensitivityAtSpecificity, SpecificityAtSensitivity\n",
        "from tensorflow.keras.losses import MeanSquaredError\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "hEQ8GsTW-T8h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Sklearn Library Imports*"
      ],
      "metadata": {
        "id": "HJxN8J9yFmAk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sklearn\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import auc, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay"
      ],
      "metadata": {
        "id": "G7-ynw_uFkcQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## *Matplotlib Library Imports*"
      ],
      "metadata": {
        "id": "QCzWrFkjSO-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "VY7kWy80_BhU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Time Libray Imports"
      ],
      "metadata": {
        "id": "X3XR7UHbGoUZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "m9tWYI38Gsz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Google Colab File Imports\n"
      ],
      "metadata": {
        "id": "-OacGHznO-kP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "import os"
      ],
      "metadata": {
        "id": "qBcEaS9MO-Y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Data from the respective test and train \"CSV\" files."
      ],
      "metadata": {
        "id": "zMNViZEA800D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J-OrRXRv8vwt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e3ad020-d9f4-44ae-a63f-4c0f4f1ea72a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
            "\n",
            " \t\t\t Train_Dataset - Shape: \t\t\t\t (11289, 2511)\n",
            "\n",
            " \t\t\t Test_Dataset - Shape: \t\t\t\t\t (7527, 2511)\n",
            "\n",
            " \t\t\t X_Train_Values - Shape: \t\t\t\t (11289, 2510)\n",
            "\n",
            " \t\t\t Y_Train_Labels - Shape: \t\t\t\t (11289,)\n",
            "\n",
            " \t\t\t Y_Train_Labels_Categorical - Shape: \t\t\t (11289, 4)\n",
            "\n",
            " \t\t\t X_Validation_Values - Shape: \t\t\t\t (3763, 2510)\n",
            "\n",
            " \t\t\t Y_Validation_Labels - Shape: \t\t\t\t (3763,)\n",
            "\n",
            " \t\t\t Y_Validation_Labels_Categorical - Shape: \t\t (3763, 4)\n",
            "\n",
            " \t\t\t X_Test_Values - Shape: \t\t\t\t (3764, 2510)\n",
            "\n",
            " \t\t\t Y_Test_Labels - Shape: \t\t\t\t (3764,)\n",
            "\n",
            " \t\t\t Y_Test_Labels_Categorical - Shape: \t\t\t (3764, 4)\n",
            "\n",
            " \t\t\t Loading Time in seconds: \t\t\t\t 64.96667385101318\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "loading_time_start = time.time()\n",
        "\n",
        "# Train_fname = '/content/drive/My Drive/Train_Test_Data/DF08/Sel_Sliced/NN_Train_Set_80_20_Selected_FilterOrder_8_Sliced.csv'\n",
        "# Test_fname = '/content/drive/My Drive/Train_Test_Data/DF08/Sel_Sliced/NN_Test_Set_80_20_Selected_FilterOrder_8_Sliced.csv'\n",
        "\n",
        "Train_fname = '/content/drive/My Drive/Train_Test_Data/DF04/All_Sliced/NN_Train_Set_60_40_All_FilterOrder_4_Sliced.csv'\n",
        "Test_fname = '/content/drive/My Drive/Train_Test_Data/DF04/All_Sliced/NN_Test_Set_60_40_All_FilterOrder_4_Sliced.csv'\n",
        "\n",
        "Train_Dataset = np.genfromtxt(Train_fname, delimiter=\",\", dtype=np.float16)\n",
        "Test_Dataset = np.genfromtxt(Test_fname, delimiter=\",\", dtype=np.float16)\n",
        "X_Train_Values = Train_Dataset[:,:-1]\n",
        "Y_Train_Labels = Train_Dataset[:,-1]\n",
        "Y_Train_Labels_Categorical = to_categorical(Train_Dataset[:,-1])\n",
        "Test_Validation_Split = int(len(Test_Dataset)/2)\n",
        "X_Validation_Values = Test_Dataset[:Test_Validation_Split,:-1]\n",
        "Y_Validation_Labels = Test_Dataset[:Test_Validation_Split,-1]\n",
        "Y_Validation_Labels_Categorical = to_categorical(Y_Validation_Labels)\n",
        "X_Test_Values = Test_Dataset[Test_Validation_Split:,:-1]\n",
        "Y_Test_Labels = Test_Dataset[Test_Validation_Split:,-1]\n",
        "Y_Test_Labels_Categorical = to_categorical(Y_Test_Labels)\n",
        "loading_time_end = time.time()\n",
        "loading_execution_time = loading_time_end-loading_time_start\n",
        "\n",
        "print(\"\\n \\t\\t\\t Train_Dataset - Shape: \\t\\t\\t\\t\",Train_Dataset.shape)\n",
        "print(\"\\n \\t\\t\\t Test_Dataset - Shape: \\t\\t\\t\\t\\t\",Test_Dataset.shape)\n",
        "print(\"\\n \\t\\t\\t X_Train_Values - Shape: \\t\\t\\t\\t\",X_Train_Values.shape)\n",
        "print(\"\\n \\t\\t\\t Y_Train_Labels - Shape: \\t\\t\\t\\t\",Y_Train_Labels.shape)\n",
        "print(\"\\n \\t\\t\\t Y_Train_Labels_Categorical - Shape: \\t\\t\\t\",Y_Train_Labels_Categorical.shape)\n",
        "print(\"\\n \\t\\t\\t X_Validation_Values - Shape: \\t\\t\\t\\t\",X_Validation_Values.shape)\n",
        "print(\"\\n \\t\\t\\t Y_Validation_Labels - Shape: \\t\\t\\t\\t\",Y_Validation_Labels.shape)\n",
        "print(\"\\n \\t\\t\\t Y_Validation_Labels_Categorical - Shape: \\t\\t\",Y_Validation_Labels_Categorical.shape)\n",
        "print(\"\\n \\t\\t\\t X_Test_Values - Shape: \\t\\t\\t\\t\",X_Test_Values.shape)\n",
        "print(\"\\n \\t\\t\\t Y_Test_Labels - Shape: \\t\\t\\t\\t\",Y_Test_Labels.shape)\n",
        "print(\"\\n \\t\\t\\t Y_Test_Labels_Categorical - Shape: \\t\\t\\t\",Y_Test_Labels_Categorical.shape)\n",
        "print(\"\\n \\t\\t\\t Loading Time in seconds: \\t\\t\\t\\t\", loading_execution_time)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Normalization for CNN, LSTM and ConvLSTM Models"
      ],
      "metadata": {
        "id": "0fPtefxKqof2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_traces_train = X_Train_Values.shape[0]\n",
        "print(\"\\n \\t\\t\\t Number of Train Traces: \\t\\t\\t\\t\", n_traces_train)\n",
        "n_features_train = X_Train_Values.shape[1]\n",
        "print(\"\\t\\t\\t Number of Train Features: \\t\\t\\t\\t\", n_features_train)\n",
        "n_output_train = len(np.unique(Y_Train_Labels))\n",
        "print(\"\\t\\t\\t Number of Output Train Labels: \\t\\t\\t\", n_output_train)\n",
        "n_output_train_categorical = len(np.unique(Y_Train_Labels_Categorical))\n",
        "print(\"\\t\\t\\t Number of Output Categorical Train Labels: \\t\\t\", n_output_train_categorical)\n",
        "\n",
        "n_trace_val = X_Validation_Values.shape[0]\n",
        "print(\"\\n \\t\\t\\t Number of Validation Traces: \\t\\t\\t\\t\", n_trace_val)\n",
        "n_features_val = X_Validation_Values.shape[1]\n",
        "print(\"\\t\\t\\t Number of Validation Features: \\t\\t\\t\", n_features_val)\n",
        "n_output_val = len(np.unique(Y_Validation_Labels))\n",
        "print(\"\\t\\t\\t Number of Output Validation Labels: \\t\\t\\t\", n_output_val)\n",
        "n_output_val_categorical = len(np.unique(Y_Validation_Labels_Categorical))\n",
        "print(\"\\t\\t\\t Number of Output Categorical Validation Labels: \\t\", n_output_val_categorical)\n",
        "\n",
        "n_trace_test = X_Test_Values.shape[0]\n",
        "print(\"\\n \\t\\t\\t Number of Test Traces: \\t\\t\\t\\t\", n_trace_test)\n",
        "n_features_test = X_Test_Values.shape[1]\n",
        "print(\"\\t\\t\\t Number of Test Features: \\t\\t\\t\\t\", n_features_test)\n",
        "n_output_test = len(np.unique(Y_Test_Labels))\n",
        "print(\"\\t\\t\\t Number of Output Test Labels: \\t\\t\\t\\t\", n_output_test)\n",
        "n_output_test_categorical = len(np.unique(Y_Test_Labels_Categorical))\n",
        "print(\"\\t\\t\\t Number of Output Categorical Test Labels: \\t\\t\", n_output_test_categorical)\n",
        "\n",
        "X_Train = X_Train_Values.reshape(n_traces_train,n_features_train,1)\n",
        "print(\"\\n \\t\\t\\t X_Train - shape: \\t\\t\\t\\t\\t\", X_Train.shape)\n",
        "X_Validate = X_Validation_Values.reshape(n_trace_val,n_features_val,1)\n",
        "print(\"\\n \\t\\t\\t X_Validate - shape: \\t\\t\\t\\t\\t\", X_Validate.shape)\n",
        "X_Test = X_Test_Values.reshape(n_trace_test,n_features_test,1)\n",
        "print(\"\\n \\t\\t\\t X_Test - shape: \\t\\t\\t\\t\\t\", X_Test.shape)"
      ],
      "metadata": {
        "id": "WBaoZ41SqoKL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83811155-5e47-4007-af1c-a17ad5970600"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " \t\t\t Number of Train Traces: \t\t\t\t 11289\n",
            "\t\t\t Number of Train Features: \t\t\t\t 2510\n",
            "\t\t\t Number of Output Train Labels: \t\t\t 4\n",
            "\t\t\t Number of Output Categorical Train Labels: \t\t 2\n",
            "\n",
            " \t\t\t Number of Validation Traces: \t\t\t\t 3763\n",
            "\t\t\t Number of Validation Features: \t\t\t 2510\n",
            "\t\t\t Number of Output Validation Labels: \t\t\t 4\n",
            "\t\t\t Number of Output Categorical Validation Labels: \t 2\n",
            "\n",
            " \t\t\t Number of Test Traces: \t\t\t\t 3764\n",
            "\t\t\t Number of Test Features: \t\t\t\t 2510\n",
            "\t\t\t Number of Output Test Labels: \t\t\t\t 4\n",
            "\t\t\t Number of Output Categorical Test Labels: \t\t 2\n",
            "\n",
            " \t\t\t X_Train - shape: \t\t\t\t\t (11289, 2510, 1)\n",
            "\n",
            " \t\t\t X_Validate - shape: \t\t\t\t\t (3763, 2510, 1)\n",
            "\n",
            " \t\t\t X_Test - shape: \t\t\t\t\t (3764, 2510, 1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Target_Names = ['Noise', 'Quake', 'Rockfall', 'Seism']\n",
        "Learning_Rate = [1e-3, 1e-4, 1e-5]\n",
        "Epochs = [10, 15, 25]\n",
        "Batch_Size = [100, 128, 150]\n",
        "\n",
        "\n",
        "\n",
        "Early_Stop = EarlyStopping(monitor='accuracy',mode='max',verbose=1,patience=5)\n",
        "\n",
        "CNN_Scores = []\n",
        "CNN_Score_Update = []\n",
        "Best_Scores = []\n",
        "Execution_Time = []\n",
        "Y_Pred = []\n",
        "CNN_Class_Y_Pred = [[]]\n",
        "\n",
        "LSTM_Scores = []\n",
        "LSTM_Score_Update = []\n",
        "LSTM_Best_Scores = []\n",
        "LSTM_Y_Pred = []\n",
        "LSTM_Class_Y_Pred = [[]]\n",
        "LSTM_Execution_Time = []\n",
        "\n",
        "\n",
        "Best_Score_Update = []"
      ],
      "metadata": {
        "id": "_98JVH69HYic"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Convolutional Neural Network (CNN)*"
      ],
      "metadata": {
        "id": "bC9_edoHJGFd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Generator"
      ],
      "metadata": {
        "id": "P5WltQAXTJa9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def CNN_Generate_Acc_Loss_Plot(History, rate, epoch, batch):\n",
        "  plt.subplot(211)\n",
        "  plt.plot(History.history['accuracy'])\n",
        "  plt.plot(History.history['val_accuracy'])\n",
        "  plt.title('Model Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Eopch')\n",
        "  plt.legend(['Training', 'Validation'], loc='best')\n",
        "        \n",
        "  plt.subplot(212)\n",
        "  plt.plot(History.history['loss'])\n",
        "  plt.plot(History.history['val_loss'])\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Validation'], loc='best')\n",
        "        \n",
        "  plt.tight_layout()\n",
        "  plt.gcf()\n",
        "  plt.savefig('/content/drive/MyDrive/dissertation_results/CNN_lr_'+str(rate)+'e_'+str(epoch)+'b_'+str(batch)+'.png', bbox_inches='tight')\n",
        "  plt.show()\n",
        "  "
      ],
      "metadata": {
        "id": "kYzrRYpQ7v9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Model_Generator(X_Train):\n",
        "  CNN_Model = Sequential()\n",
        "  CNN_Model.add(Conv1D(filters=16, kernel_size=3,  activation='relu', padding='same'))\n",
        "  CNN_Model.add(Conv1D(filters=16, kernel_size=3,  activation='relu', padding='same'))\n",
        "  CNN_Model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
        "  CNN_Model.add(Conv1D(filters=32, kernel_size=3,  activation='relu', padding='same'))\n",
        "  CNN_Model.add(Conv1D(filters=32, kernel_size=3,  activation='relu', padding='same'))\n",
        "  CNN_Model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
        "  CNN_Model.add(Conv1D(filters=64, kernel_size=3,  activation='relu', padding='same'))\n",
        "  CNN_Model.add(MaxPooling1D(pool_size=2, padding='same'))\n",
        "  CNN_Model.add(Flatten())\n",
        "  CNN_Model.add(Dense(units=16, activation='relu'))\n",
        "  CNN_Model.add(BatchNormalization())\n",
        "  CNN_Model.add(Dense(units=8, activation='relu'))\n",
        "  CNN_Model.add(BatchNormalization())\n",
        "  CNN_Model.add(Dense(4, activation='softmax'))\n",
        "  \n",
        "  CNN_Model.build(X_Train.shape)\n",
        "  CNN_Model.summary()\n",
        "  return CNN_Model\n"
      ],
      "metadata": {
        "id": "N5DbfAiC9U-m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "80RyZXd6FmD6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for rate in Learning_Rate:\n",
        "  for epoch in Epochs:\n",
        "    for batch in Batch_Size:\n",
        "      training_time_start = time.time()\n",
        "      CNN_Model = Model_Generator(X_Train)\n",
        "      CNN_Model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=rate),\n",
        "                        loss=tf.keras.losses.MeanSquaredError(), \n",
        "                        metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "      History_Model = CNN_Model.fit(x=X_Train, y=Y_Train_Labels_Categorical, \n",
        "                                    epochs=epoch, batch_size=batch,\n",
        "                                    validation_data=(X_Validate, Y_Validation_Labels_Categorical))\n",
        "      CNN_Scores.append(CNN_Model.evaluate(X_Validate, Y_Validation_Labels_Categorical, batch_size=batch))\n",
        "      Best_Scores.append(max(History_Model.history.get('accuracy')))\n",
        "      Y_Pred.append(CNN_Model.predict(X_Test))\n",
        "      training_time_end = time.time()\n",
        "      training_execution_time = training_time_end-training_time_start\n",
        "      Execution_Time.append(training_execution_time)\n",
        "      \n",
        "      CNN_Generate_Acc_Loss_Plot(History_Model, rate, epoch, batch)"
      ],
      "metadata": {
        "id": "yer5lnLUFk-i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82829e0d-8818-4f41-ec50-93623fb2cd44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_35 (Conv1D)          (11289, 2510, 16)         64        \n",
            "                                                                 \n",
            " conv1d_36 (Conv1D)          (11289, 2510, 16)         784       \n",
            "                                                                 \n",
            " max_pooling1d_21 (MaxPoolin  (11289, 1255, 16)        0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_37 (Conv1D)          (11289, 1255, 32)         1568      \n",
            "                                                                 \n",
            " conv1d_38 (Conv1D)          (11289, 1255, 32)         3104      \n",
            "                                                                 \n",
            " max_pooling1d_22 (MaxPoolin  (11289, 628, 32)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " conv1d_39 (Conv1D)          (11289, 628, 64)          6208      \n",
            "                                                                 \n",
            " max_pooling1d_23 (MaxPoolin  (11289, 314, 64)         0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (11289, 20096)            0         \n",
            "                                                                 \n",
            " dense_21 (Dense)            (11289, 16)               321552    \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (11289, 16)              64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_22 (Dense)            (11289, 8)                136       \n",
            "                                                                 \n",
            " batch_normalization_15 (Bat  (11289, 8)               32        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dense_23 (Dense)            (11289, 4)                36        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 333,548\n",
            "Trainable params: 333,500\n",
            "Non-trainable params: 48\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "113/113 [==============================] - 3s 18ms/step - loss: nan - accuracy: 0.2366 - val_loss: nan - val_accuracy: 0.2333\n",
            "Epoch 2/10\n",
            "113/113 [==============================] - 2s 16ms/step - loss: nan - accuracy: 0.2366 - val_loss: nan - val_accuracy: 0.2333\n",
            "Epoch 3/10\n",
            "113/113 [==============================] - 2s 16ms/step - loss: nan - accuracy: 0.2366 - val_loss: nan - val_accuracy: 0.2333\n",
            "Epoch 4/10\n",
            "113/113 [==============================] - 2s 15ms/step - loss: nan - accuracy: 0.2366 - val_loss: nan - val_accuracy: 0.2333\n",
            "Epoch 5/10\n",
            "113/113 [==============================] - 2s 15ms/step - loss: nan - accuracy: 0.2366 - val_loss: nan - val_accuracy: 0.2333\n",
            "Epoch 6/10\n",
            "113/113 [==============================] - 2s 15ms/step - loss: nan - accuracy: 0.2366 - val_loss: nan - val_accuracy: 0.2333\n",
            "Epoch 7/10\n",
            "105/113 [==========================>...] - ETA: 0s - loss: nan - accuracy: 0.2360"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-ce4ed0791c2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m       History_Model = CNN_Model.fit(x=X_Train, y=Y_Train_Labels_Categorical, \n\u001b[1;32m     10\u001b[0m                                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                                     validation_data=(X_Validate, Y_Validation_Labels_Categorical))\n\u001b[0m\u001b[1;32m     12\u001b[0m       \u001b[0mCNN_Scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCNN_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_Validate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_Validation_Labels_Categorical\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m       \u001b[0mBest_Scores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mHistory_Model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Score Calculations"
      ],
      "metadata": {
        "id": "pYV-56e4TPPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(CNN_Scores))\n",
        "for i in range(len(CNN_Scores)):\n",
        "   temp = str(CNN_Scores[i]).replace(\"[\",\"\").replace(\"]\",\"\").replace(\" \",\"\")\n",
        "   CNN_Score_Update.append(temp.split(\",\"))"
      ],
      "metadata": {
        "id": "ld73dygvTfto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "for rate in Learning_Rate:\n",
        "  for epoch in Epochs:\n",
        "    for batch in Batch_Size:\n",
        "      if (float(CNN_Score_Update[i][3])+float(CNN_Score_Update[i][4]) == 0):\n",
        "        CNN_F1_Score = 0\n",
        "      else:\n",
        "        CNN_F1_Score = 2*((float(CNN_Score_Update[i][3])*float(CNN_Score_Update[i][4]))/(float(CNN_Score_Update[i][3])+float(CNN_Score_Update[i][4])))\n",
        "      print(\"\\t\\t\\t CNN Scores - Learning_Rate=%f, Epoch=%d, Batch=%d \\t\\t\\t\" % (rate, epoch, batch))\n",
        "      print(\"CNN Mean Square Error: \\t\\t\\t\", CNN_Score_Update[i][0])\n",
        "      print(\"CNN Validation Accuracy Score: \\t\\t\", CNN_Score_Update[i][1])\n",
        "      print(\"CNN Best Training Accuracy Score: \\t\", Best_Scores[i])    \n",
        "      print(\"CNN F1 Score: \\t\\t\\t\\t\", CNN_F1_Score)\n",
        "      print(\"CNN Precision Score: \\t\\t\\t\", CNN_Score_Update[i][3])\n",
        "      print(\"CNN Recall Score: \\t\\t\\t\", CNN_Score_Update[i][4])\n",
        "      print(\"CNN AUC Score: \\t\\t\\t\\t\", CNN_Score_Update[i][2])\n",
        "      print(\"Execution Time: \\t\\t\\t\", Execution_Time[i])\n",
        "      print(\"\\n\\n\\n\")      \n",
        "      i = i+1"
      ],
      "metadata": {
        "id": "obCPxegfHgE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC Curves Plot"
      ],
      "metadata": {
        "id": "gwZA-XJ1TUOw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_Test_Labels_Bin = label_binarize(Y_Test_Labels, classes=[0.0, 1.0, 2.0, 3.0])\n",
        "Num_Classes = Y_Test_Labels_Bin.shape[1]\n",
        "lw_list = [4, 3, 2, 1]\n",
        "color_list = ['red','blue','yellow','green']\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "thres_r = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "\n",
        "for k in range(len(Y_Pred)):\n",
        "  for i in range(Num_Classes):\n",
        "    fpr[i], tpr[i], thres_r[i] = roc_curve(Y_Test_Labels_Bin[:, i], Y_Pred[k][:, i])\n",
        "    plt.plot(fpr[i], tpr[i], color=color_list[i], lw=lw_list[i])\n",
        "  plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Receiver Operating Characteristic Curves')\n",
        "  plt.legend(Target_Names)\n",
        "  plt.gcf()\n",
        "  plt.savefig('/content/drive/MyDrive/dissertation_results/CNN_roc_Y_Pred'+str(k)+'.png', bbox_inches='tight')\n",
        "  plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "UiKY4lqjTggn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(len(Y_Pred)):\n",
        "  for i in range(Num_Classes):\n",
        "    fpr[i], tpr[i], thres_r[i] = roc_curve(Y_Test_Labels_Bin[:, i], Y_Pred[k][:, i])\n",
        "    print('AUC for Class {}: {}'.format(Target_Names[i], auc(fpr[i], tpr[i])))\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "KFdubbsAwtKI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# *Long Short-Term Memory Neural Network (LSTM)*"
      ],
      "metadata": {
        "id": "_qnSSZ3wkbw7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Generator"
      ],
      "metadata": {
        "id": "OnQaOZ8KkmS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_Generate_Acc_Loss_Plot(History, rate, epoch, batch):\n",
        "  plt.subplot(211)\n",
        "  plt.plot(History.history['accuracy'])\n",
        "  plt.plot(History.history['val_accuracy'])\n",
        "  plt.title('Model Accuracy')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Eopch')\n",
        "  plt.legend(['Training', 'Validation'], loc='best')\n",
        "        \n",
        "  plt.subplot(212)\n",
        "  plt.plot(History.history['loss'])\n",
        "  plt.plot(History.history['val_loss'])\n",
        "  plt.title('Model Loss')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Validation'], loc='best')\n",
        "        \n",
        "  plt.tight_layout()\n",
        "  plt.gcf()\n",
        "  plt.savefig('/content/drive/MyDrive/dissertation_results/LSTM_lr_'+str(rate)+'e_'+str(epoch)+'b_'+str(batch)+'.png', bbox_inches='tight')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "oGTk1MElo74G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def LSTM_Model_Generator(X_Train):\n",
        "  LSTM_Model = Sequential()\n",
        "  LSTM_Model.add(LSTM(units=64, activation='tanh', return_sequences=True, input_shape=(X_Train.shape[1], X_Train.shape[2])))\n",
        "  LSTM_Model.add(Dropout(0.2))\n",
        "  LSTM_Model.add(Flatten())\n",
        "  LSTM_Model.add(BatchNormalization())\n",
        "  LSTM_Model.add((Dense(units=4,  activation='softmax')))\n",
        "  LSTM_Model.build(X_Train.shape)\n",
        "  LSTM_Model.summary()\n",
        "  return LSTM_Model"
      ],
      "metadata": {
        "id": "tBy3hxSBkqR6",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Training"
      ],
      "metadata": {
        "id": "1jYlLHQ1kqpG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for rate in Learning_Rate:\n",
        "  for epoch in Epochs:\n",
        "    for batch in Batch_Size:\n",
        "      training_time_start = time.time()\n",
        "      LSTM_Model = LSTM_Model_Generator(X_Train)\n",
        "      LSTM_Model.compile(optimizer= tf.keras.optimizers.Adam(learning_rate=rate),\n",
        "                        loss=tf.keras.losses.MeanSquaredError(), \n",
        "                        metrics=['accuracy', tf.keras.metrics.AUC(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "      LSTM_History = LSTM_Model.fit(x=X_Train, y=Y_Train_Labels_Categorical, \n",
        "                                    epochs=epoch, batch_size=batch,\n",
        "                                    validation_data=(X_Validate, Y_Validation_Labels_Categorical),\n",
        "                                    callbacks=[Early_Stop])\n",
        "      LSTM_Scores.append(LSTM_Model.evaluate(X_Validate, Y_Validation_Labels_Categorical, batch_size=batch))\n",
        "      LSTM_Best_Scores.append(max(LSTM_History.history.get('accuracy')))\n",
        "      LSTM_Y_Pred.append(LSTM_Model.predict(X_Test))\n",
        "      training_time_end = time.time()\n",
        "      training_execution_time = training_time_end-training_time_start\n",
        "      LSTM_Execution_Time.append(training_execution_time)\n",
        "      LSTM_Generate_Acc_Loss_Plot(LSTM_History, rate, epoch, batch)"
      ],
      "metadata": {
        "id": "o41ntOwwkr1i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Score Calculations"
      ],
      "metadata": {
        "id": "q1y4Gtg3ksH3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(LSTM_Scores))\n",
        "for i in range(len(LSTM_Scores)):\n",
        "  temp = str(LSTM_Scores[i]).replace(\"[\",\"\").replace(\"]\",\"\").replace(\" \",\"\")\n",
        "  LSTM_Score_Update.append(temp.split(\",\"))"
      ],
      "metadata": {
        "id": "oRdjZDSGlaCs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "i=0\n",
        "\n",
        "for rate in Learning_Rate:\n",
        "  for epoch in Epochs:\n",
        "    for batch in Batch_Size:\n",
        "      if (float(LSTM_Score_Update[i][3])+float(LSTM_Score_Update[i][4]) == 0):\n",
        "        LSTM_F1_Score = 0\n",
        "      else:\n",
        "        LSTM_F1_Score = 2*((float(LSTM_Score_Update[i][3])*float(LSTM_Score_Update[i][4]))/(float(LSTM_Score_Update[i][3])+float(LSTM_Score_Update[i][4])))\n",
        "      print(\"\\t\\t\\t LSTM Scores - Learning_Rate=%f, Epoch=%d, Batch=%d\" % (rate, epoch, batch))\n",
        "      print(\"LSTM Mean Square Error: \\t\\t\\t\", LSTM_Score_Update[i][0])\n",
        "      print(\"LSTM Accuracy Score: \\t\\t\\t\\t\", LSTM_Score_Update[i][1])\n",
        "      print(\"LSTM Best Training Accuracy Score: \\t\\t\", LSTM_Best_Scores[i]) \n",
        "      print(\"LSTM F1 Score: \\t\\t\\t\\t\\t\", LSTM_F1_Score)\n",
        "      print(\"LSTM Precision Score: \\t\\t\\t\\t\", LSTM_Score_Update[i][3])\n",
        "      print(\"LSTM Recall Score: \\t\\t\\t\\t\", LSTM_Score_Update[i][4])\n",
        "      print(\"LSTM AUC Score: \\t\\t\\t\\t\", LSTM_Score_Update[i][2])\n",
        "      print(\"LSTM Execution Time: \\t\\t\\t\\t\", LSTM_Execution_Time[i])\n",
        "      print(\"\\n\\n\\n\")\n",
        "      i = i+1"
      ],
      "metadata": {
        "id": "3-OCcQKXlZ0E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROC Curves Plot"
      ],
      "metadata": {
        "id": "oFDA8SEZlFFW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y_Test_Labels_Bin = label_binarize(Y_Test_Labels, classes=[0.0, 1.0, 2.0, 3.0])\n",
        "Num_Classes = Y_Test_Labels_Bin.shape[1]\n",
        "\n",
        "fpr = dict()\n",
        "tpr = dict()\n",
        "thres_r = dict()\n",
        "roc_auc = dict()\n",
        "\n",
        "\n",
        "for k in range(len(LSTM_Y_Pred)):\n",
        "  for i in range(Num_Classes):\n",
        "    fpr[i], tpr[i], thres_r[i] = roc_curve(Y_Test_Labels_Bin[:, i], LSTM_Y_Pred[k][:, i])\n",
        "    plt.plot(fpr[i], tpr[i], color=color_list[i], lw=lw_list[i])\n",
        "\n",
        "  plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "  plt.xlim([0.0, 1.0])\n",
        "  plt.ylim([0.0, 1.05])\n",
        "  plt.xlabel('False Positive Rate')\n",
        "  plt.ylabel('True Positive Rate')\n",
        "  plt.title('Receiver Operating Characteristic Curves')\n",
        "  plt.legend(Target_Names)\n",
        "  plt.gcf()\n",
        "  plt.savefig('/content/drive/MyDrive/dissertation_results/LSTM_roc_Y_Pred'+str(k)+'.png', bbox_inches='tight')\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "zDU9iB1Pndfl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for k in range(len(LSTM_Y_Pred)):\n",
        "  for i in range(Num_Classes):\n",
        "    fpr[i], tpr[i], thres_r[i] = roc_curve(Y_Test_Labels_Bin[:, i], LSTM_Y_Pred[k][:, i])\n",
        "    print('LSTM AUC for Class {}: {}'.format(Target_Names[i], auc(fpr[i], tpr[i])))\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "id": "CpbalVDNwGsm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}